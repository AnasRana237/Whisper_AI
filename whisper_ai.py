# -*- coding: utf-8 -*-
"""Whisper_AI.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1J6skgs-Caehu25Prdn16Wp5CnKuSCxqW
"""

!pip install openai-whisper gradio librosa yake torch torchaudio

import whisper
import gradio as gr
import librosa
import yake

def transcribe_audio(audio_path):
    model = whisper.load_model("base")  # You can change "base" to "small", "medium", etc.
    result = model.transcribe(audio_path)
    text = result["text"]
    duration = librosa.get_duration(filename=audio_path)
    words_per_second = len(text.split()) / duration if duration > 0 else 0
    keywords = extract_keywords(text)
    return text, f"Speech Speed: {words_per_second:.2f} words/sec", f"Keywords: {', '.join(keywords)}"

def extract_keywords(text):
    kw_extractor = yake.KeywordExtractor()
    keywords = kw_extractor.extract_keywords(text)
    return [kw[0] for kw in keywords[:5]]

# Gradio Interface
def gradio_app():
    iface = gr.Interface(
        fn=transcribe_audio,
        inputs="file",
        outputs=["text", "text", "text"],
        title="Whisper AI Transcription with Extra Features",
        description="Upload an audio file to transcribe, analyze speech speed, and extract keywords."
    )
    iface.launch()

if __name__ == "__main__":
    gradio_app()